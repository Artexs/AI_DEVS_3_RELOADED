Zadanie: Z przechwyconych materiałów interesuje nas tylko jedna z publikacji profesora Maja. Nasza centrala chce pozyskać odpowiedzi na dostarczone przez nią pytania. Zwróć proszę uwagę, że podlinkowana notatka zawiera treści tekstowe, graficzne i dźwiękowe. Istnieje ogromne prawdopodobieństwo, że konieczne będzie wzięcie pod uwagę informacji podanych w każdym formacie. Zadanie, do którego raportujesz odpowiedź nazywa się “arxiv”.

Link do artykułu: https://c3ntrala.ag3nts.org/dane/arxiv-draft.html

Pytania centrali: https://c3ntrala.ag3nts.org/data/KLUCZ-API/arxiv.txt

Oczekiwany format odpowiedzi:

{
    "ID-pytania-01": "krótka odpowiedź w 1 zdaniu",
    "ID-pytania-02": "krótka odpowiedź w 1 zdaniu",
    "ID-pytania-03": "krótka odpowiedź w 1 zdaniu",
    "ID-pytania-NN": "krótka odpowiedź w 1 zdaniu"
}




Co należy zrobić w zadaniu?

Centrala przechwyciła materiały profesora Maja i potrzebuje odpowiedzi na kilka pytań. Twoim zadaniem jest zbadanie artykułu profesora, uwzględniając tekst, grafiki i dźwięki, a następnie odpowiedzenie na pytania centrali. Pamiętaj o kontekście!

Kroki do wykonania:





Pobierz dane:





Artykuł profesora Maja: https://c3ntrala.ag3nts.org/dane/arxiv-draft.html



Pytania centrali (dostępne po podaniu klucza API): https://c3ntrala.ag3nts.org/data/KLUCZ-API/arxiv.txt  (zastąp `KLUCZ-API` swoim kluczem).



Zindeksuj artykuł: 
* Tekst: Przetwórz treść HTML - usuń zbędne tagi i formatowanie. Możesz użyć konwertera HTML do MD dostępnego w Twoim języku programowania. 
* Grafiki: Pobierz obrazy. Użyj modelu LLM Vision do wygenerowania opisów obrazów. Pamiętaj o kontekście – uwzględnij np. podpisy pod zdjęciami.
* Dźwięki: Pobierz pliki dźwiękowe (MP3). Użyj narzędzia do transkrypcji mowy na tekst (np. Whisper) aby przekonwertować dźwięk na tekst.
* Zapisz wszystko w jednym pliku: Stwórz jeden plik (np. Markdown), który zawiera:
    * Przetworzony tekst artykułu. 
    * Opisy obrazów (zamiast samych obrazów). 
    * Transkrypcje nagrań (zamiast plików dźwiękowych).



Odpowiedz na pytania: Użyj modelu LLM i przygotowanego pliku Markdown jako kontekstu. Wygeneruj krótkie, jednozdaniowe odpowiedzi na pytania centrali.

4. Wyślij odpowiedź: Wyślij odpowiedzi w formacie JSON. Format odpowiedzi:

{
      "task": "arxiv",
      "apikey": "YOUR_API_KEY",
      "answer": {
        "01": "krótka odpowiedź w 1 zdaniu",
        "02": "krótka odpowiedź w 1 zdaniu",
        "03": "krótka odpowiedź w 1 zdaniu",
        [...]
    }
}

Wskazówki:





Kontekst jest kluczowy: Zwróć uwagę na kontekst, w jakim pojawiają się grafiki i dźwięki. Podpisy pod zdjęciami i otaczający tekst mogą zawierać istotne informacje.



Limit tokenów: Upewnij się, że cały tekst (artykuł + opisy + transkrypcje) mieści się w limicie tokenów wybranego modelu LLM. Jeśli przekraczasz limit, skróć opisy lub transkrypcje. Możesz też podzielić artykuł na mniejsze części



Cache: Zapisuj wyniki pośrednie (opisy obrazów, transkrypcje) w cache, aby nie generować ich za każdym razem od nowa. Cache to może być po prostu zestaw plików tekstowych.



Pętla zwrotna: Jeśli Centrala stwierdziła że odpowiedź na któreś pytanie jest nieprawidłowa, dodaj tą informację wraz z nieprawidłową odpowiedzią do kontekstu przy kolejnym zapytaniu. W ten sposób uniekniesz powtarzania tego samego błędu. 



Potencjalne problemy:





Kod błędu -301: Sprawdź, czy wysyłasz obiekt JSON, a nie zakodowany string JSON.



Kod błędu -302: Sprawdź, czy wysyłasz odpowiednią liczbę odpowiedzi.



Niepoprawne odpowiedzi: Czasami model może się pomylić. Spróbuj doprecyzować prompt lub dodać informację o błędnej odpowiedzi jako kontekst w kolejnym zapytaniu.



Dokumentacja Swagger:

https://c3ntrala.ag3nts.org/swagger/?spec=S02E05-xcvbyuitafjkl.json 